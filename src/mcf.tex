\documentclass[UTF8,a4paper]{ctexart}
\usepackage{taoda}
\usepackage[lmargin=2cm,rmargin=2cm,tmargin=2cm,bmargin=2cm]{geometry}

\title{Notes on Minimal Cost Flow}
\author{陶大}

\begin{document}

\maketitle
\tableofcontents

\section{Definitions and Properties}

For a directed graph $G=(V, E)$, there is nonnegative capacity $u_e$ associated with each edge
and balance $b_v$ with each vertex.
For a flow over edge $e$, each unit costs $c_e$.

\[
    \min \sum_{e\in E} c_e x_e
\]
s.t.,
\begin{align}
    0\leqslant x_e \leqslant u_e,\qquad \forall e\in E\\
    \sum_{e\text{ from }v} x_e - \sum_{e\text{ into }v} x_e = b_v,\qquad \forall v\in V
\end{align}

Vertices with positive $b_v$ are called \emph{supplies},
and those with negative ones, \emph{demands}.
Solutions satisfy constraints are \emph{feasible}.

Without loss of generality, we can assume there is exactly one supply and one demand.
They are called the \emph{source} and the \emph{sink} respectively.

\begin{remark}
    Please notice, that $\vec{b}$ \emph{equals with} the net out-flows.
    This is a constraint in minimal-cost flow problem.
    This is not the same as the settings in maximal flow problem.
\end{remark}

\begin{remark}
    Usually, we are interested in min-cost max-flow problem.

    Let $G=(V, E, {u_e}, {c_e}, {b_v})$ be a MCF setting with a single source and a single sink,
    where a min-cost max flow is desired.
    Then we construct $G'=(V', E', {u'_e}, {c'_e}, {b'_v})$ as follows.
    \begin{align}
        V'&=V,\\
        E'&=E\cup\{e'\},\\
        u'_e&=\begin{cases}
            u_e,&\forall e\in E,\\
            +\infty,&e',
        \end{cases}\\
        c'_e&=\begin{cases}
            c_e,&\forall e\in E,\\
            -C,&e',
        \end{cases}\\
        b'_v&=\vec{0}
    \end{align}
    where $e'$ connects the only sink back to the source,
    and $C$ is a large enough (so $c'_e$ is overwhelmingly small).

    To minimize the total cost, flow over $e'$ must be maximal.
    Typically, $C=\sum_{e\in E}\abs{c_e}$.
\end{remark}

\begin{definition}[Residual network]
    Let $G=(V, E)$ a directed graph with capacities $\vec{u}$ and $\vec{x}$ a feasible flow over it.
    Then the residual network $R(x)=(V', E')$ is also a directed graph with capacities $\vec{u'}$.
    They share the same set of vertices.
    But for each edge $e\in E$, there are two edges $e$ and $\inv{e}$ in $E'$.
    One is forward, with residual capacity $u_e-x_e$;
    the other is backward, with capacity $x_e$.
    \begin{align*}
        V' &=V,\\
        E' &=\brace{e,\inv{e} \mid e\in E},\\
        u'_e &=\begin{cases}
            u_e-x_e,&e\in E\\
            x_e,&\inv{e}\in E
        \end{cases}
    \end{align*}
    where $\inv{e}$ stands for the inverse of edge $e$
    (Suppose $e$ connects $v_0$ to $v_1$, then $\inv{e}$ connects $v_1$ to $v_0$.)

    Intuitively, because the residual graph shares the same vertices with the original graph,
    they also share the same balance condition.
    Once there is a path from a source to a sink in the residual graph,
    we can adjust flow in the original graph alongside this path by one unit and keep the balance condition.
\end{definition}

\begin{definition}[Path and circle flow]
    A path (or circle) flow is an acyclic path (or simple cycle) with a same amount of flows in each edge.
\end{definition}

\begin{lemma}[Flow Decomposition]
    Every positively flowed graph can be represented by a set of positive path flows and cycle flows.
    \begin{itemize}
        \item every path flow starts from a supply and ends at a demand.
        \item At most $\abs{V}+\abs{E}$ paths and cycles have nonzero flow; among them, at most $\abs{E}$ cycles have nonzero flow.
    \end{itemize}
\end{lemma}

\begin{lemma}[Augmenting Cycle Theorem]
    Let $x$ and $x^\circ$ be any two feasible solutions of a network flow problem.
    Then $x$ equals $x^\circ$ plus the flow on at most $\abs{E}$ cycles in residual graph $R(x^\circ)$.
    Furthermore, the cost of $x$ equals with that of $x^\circ$ plus those of these augmenting cycles.
\end{lemma}

These lemmas imply the following interesting theorem.

\begin{theorem}[Negative Cycle Optimality Theorem]
    A feasible solution of minimum cost flow problem is optimal if and only if the residual network contains no negative cost cycles.
\end{theorem}

\begin{definition}
    Let $\pi$ associate every vertex with a real number.
    We call $\pi(v)$ the \emph{node potential} of $v$.
    Then we define the \emph{reduced cost} $c^\pi$ induced by node potential $\pi$ by
    \begin{align}
        c^\pi_e&=c_e + \pi(j) - \pi(i) &\forall e\in E
    \end{align}
    where $i$ is the source of $e$ and $j$ the sink of that.

    It is easy to see,
    \begin{enumerate}
        \item For any path $P$ from $i$ to $j$, $\sum_{e\in P}c^\pi_e = \sum_{e\in P}c_e + \pi(j) - \pi(i)$.
        \item For any cycle $P$, $\sum_{e\in P}c^\pi_e = \sum_{e\in P} c_e$.
    \end{enumerate}

    Let $z_\pi(\cdot)$ be the objective function of MCF problem with costs $c^\pi$.
    By noticing that $c^\pi=c$ when $\pi=\vec{0}$, $z_{\vec{0}}$ is the original objective function.
    Then we have
    \[
        z_{\vec{0}}(x)-z_\pi(x)=\sum_{v\in V}\pi(v)b_v, \qquad \forall\text{ feasible solution } x
    \]
    For any vertex $v$, increasing its node potential from $0$ to $\pi(v)$ means
    \begin{itemize}
        \item Cost of every unit going into it increases $\pi(v)$;
        \item and cost of going-away unit decreases $\pi(v)$.
    \end{itemize}
    Then the net profit of $v$ is $b_v\pi(v)$.

    Because $\sum_{v\in V}\pi(v)b_v$ is a constant w.r.t.\ $x$, a flow minimizing $z_\pi$ also minimizes $z_{\vec{0}}$.
\end{definition}

\begin{theorem}{Reduced Cost Optimality Theorem}
    A feasible solution $x$ is optimal iff there is a $\pi$ such that $c^\pi(e)\geq 0$ for all edge $e\in R(x)$.
\end{theorem}

There is an intuitive interpretation behind reduced-cost optimality.
Let $\mu(i)=-\pi(i)$ for all $i\in G$ as the cost of obtaining one unit of the commodity at $i$.
Then RCO theorem says, that cost difference between $i$ and $j$ is no more than that of transporting a unit from $i$ to $j$.

\begin{theorem}{Complementary Slackness Optimality Conditions}
    A feasible solution $x$ is optimal iff
    there is a node potential $\pi$ such that
    \begin{align}
        x^\pi_e &=0, \qquad\text{if }c^\pi_e > 0\\
        c^\pi_e &=0, \qquad\text{if }0 < x^\pi_e < u_e\\
        x^\pi_e &=u_e, \qquad\text{if }c^\pi_e < 0
    \end{align}
\end{theorem}

\begin{definition}[Dual Minimum Cost Flow Problem]
    For a MCF problem $(\brace{u_e}_{e\in E}, \brace{c_e}_{e\in E}, \brace{b_v}_{v\in V})$,
    its dual problem is
    \[
        \max w(\pi, \alpha)=\sum_{v\in V}b_v\pi(v) - \sum_{e\in E}u_e\alpha_e
    \]
    subject to
    \begin{align}
        \pi(i) - \pi(j) - \alpha_e &\leq c_e, \qquad\forall e\in E\text{ and $e$ goes from $i$ to $j$}\\
        \alpha_e&\geq 0, \qquad\forall e\in E
    \end{align}
    We will see later, $\pi$ here is node potential.
\end{definition}

\begin{theorem}[Weak Duality Theorem]
    Let $z(\cdot)$ be the objective function of a MCF problem, and $w(\cdot, \cdot)$ be that of it dual problem.
    Then for all feasible solution $x$ to the primal problem and $(\pi, \alpha)$ to the dual one,
    \[
        w(\pi,\alpha)\leq z(x)
    \]
\end{theorem}

\begin{theorem}[Strong Duality Theorem]
    Let $z$ be the objective function of a MCF problem and $w$ that of its dual problem.
    If the primal problem is solvable,
    then there is a solution $x$ to the primal problem and a solution $\pi$ to the dual problem satisfying
    $z(x)=w(\pi, \alpha)$ where $\alpha_e = \max\brace{0, -c^\pi_e}$.

    We just simply write $w(\pi)$ if $\alpha$ is set in this way.
\end{theorem}

\begin{theorem}
    Let $x$ be an optimal solution to the MCF problem and $\pi$ be an optional solution to the dual problem.
    Then the pair $(x, \pi)$ statisfies the complementary slackness optimality conditions.
\end{theorem}

\section{Applications}

\subsection{Linear programs with consecutive 1's in columns}

Let us take a look at an example.
\[
    \min \vec{c}\cdot \vec{x}
\]
s.t.
\begin{align*}
    \begin{bmatrix}
        0&1&0&1&1\\
        1&1&0&0&1\\
        1&1&1&0&0\\
        1&1&1&0&0
    \end{bmatrix}
    \vec{x} &\geq \begin{bmatrix}
        5\\
        12\\
        10\\
        6
    \end{bmatrix}
    \\
    \vec{x}&\geq \vec{0}
\end{align*}

We first make the first constraint into an equality by introducing surplus variable $y$,
and then a redundant row $\vec{0}\cdot \vec{x} + \vec{0}\cdot \vec{y}=\vec{0}$.
So we get
\begin{align*}
    \begin{bmatrix}
        0&1&0&1&1& -1&0&0&0\\
        1&1&0&0&1& 0&-1&0&0\\
        1&1&1&0&0& 0&0&-1&0\\
        1&1&1&0&0& 0&0&0&-1\\
        0&0&0&0&0& 0&0&0&0
    \end{bmatrix}
    \begin{bmatrix}
        \vec{x}\\
        \vec{y}
    \end{bmatrix}
    &=\begin{bmatrix}
        5\\
        12\\
        10\\
        6\\
        0
    \end{bmatrix}
    \\ \vec{x}&\geq \vec{0}
    \\ \vec{y}&\geq \vec{0}
\end{align*}

Then we perform the following operation from bottom to up:
we subtract row $i$ by row $i-1$ for each $i$.
So we get
\[
    \min \vec{c}\cdot\vec{x}
\]
s.t.
\begin{align*}
    \begin{bmatrix}
        0&1&0&1&1& -1&0&0&0\\
        1&0&0&-1&0& 1&-1&0&0\\
        0&0&1&0&-1& 0&1&-1&0\\
        0&0&0&0&0& 0&0&1&-1\\
        -1&-1&-1&0&0& 0&0&0&1
    \end{bmatrix}
    \begin{bmatrix}
        \vec{x}\\
        \vec{y}
    \end{bmatrix}
    &=\begin{bmatrix}
        5\\
        7\\
        -2\\
        -4\\
        -6
    \end{bmatrix}
    \\ \vec{x}&\geq \vec{0}
    \\ \vec{y}&\geq \vec{0}
\end{align*}
This is actually a MCF problem illustrated by Fig~\ref{fig:app:lp}.

\begin{figure}
    \begin{center}
        \includegraphics{fig/application-lp.pdf}
    \end{center}
    \caption{Formulating a linear program with consecutive 1's as a MCF problem}
    \label{fig:app:lp}
\end{figure}

\section{Algorithms}

\end{document}
